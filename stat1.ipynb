{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357a03dc-2076-43af-9060-233e18f0f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0b0742-7174-4f91-93da-c7c59f715229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def format_value_with_uncertainty(value, variance, sample_size):\n",
    "    def round_to_one_significant(x):\n",
    "        if x == 0:\n",
    "            return 0.0\n",
    "        exponent = np.floor(np.log10(abs(x)))\n",
    "        mantissa = x / (10 ** exponent)\n",
    "        rounded_mantissa = np.round(mantissa)\n",
    "        if rounded_mantissa == 10:\n",
    "            rounded_mantissa = 1\n",
    "            exponent += 1\n",
    "        return rounded_mantissa * (10 ** exponent)\n",
    "    \n",
    "    def get_decimal_places(x):\n",
    "        s = \"{0:.10f}\".format(x).rstrip('0').rstrip('.')\n",
    "        return len(s.split('.')[1]) if '.' in s else 0\n",
    "    \n",
    "    std_dev = np.sqrt(variance)\n",
    "    standard_error = std_dev / np.sqrt(sample_size)\n",
    "    \n",
    "    if standard_error == 0:\n",
    "        return f\"{round(value):.0f} ± 0\"\n",
    "    \n",
    "    rounded_uncertainty = round_to_one_significant(standard_error)\n",
    "    decimal_places = get_decimal_places(rounded_uncertainty)\n",
    "    \n",
    "    formatted_value = round(value, decimal_places)\n",
    "    formatted_uncertainty = round(rounded_uncertainty, decimal_places)\n",
    "    \n",
    "    return f\"{formatted_value:.{decimal_places}f} ± {formatted_uncertainty:.{decimal_places}f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a015e17c-4679-44ea-a198-0a4983f8fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hist_dencity(dist, plot_range, save_path):\n",
    "    a = dict()\n",
    "    a[10] = dist.rvs(10)\n",
    "    a[50] = dist.rvs(50)\n",
    "    a[1000] = dist.rvs(1000)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "    for num, ax in zip(a.keys(), axes):\n",
    "        ax.set_title(f'Number of samples {num}')\n",
    "        if isinstance(dist.dist, stats.rv_continuous):\n",
    "            ax.hist(a[num], bins=np.sqrt(num).astype(int), range=plot_range, density=True, color='blue', alpha=0.5)\n",
    "            x = np.linspace(plot_range[0], plot_range[1], num=int(1e5))\n",
    "            ax.plot(x, dist.pdf(x), color='red')\n",
    "        else:\n",
    "            x = np.arange(plot_range[0], plot_range[1])\n",
    "            ax.hist(a[num], bins=min(np.sqrt(num).astype(int), (plot_range[1]-plot_range[0])), range=plot_range, density=True, color='blue', alpha=0.5)\n",
    "            ax.plot(x, dist.pmf(x))\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def q_mid(x):\n",
    "    return np.percentile(x, [75, 25]).mean()\n",
    "\n",
    "def statistics(dist):\n",
    "    stats = np.empty((3, 6, 1000))\n",
    "    for i in range(1000):\n",
    "        a = dict().fromkeys(range(3))\n",
    "        a[0] = dist.rvs(10)\n",
    "        a[1] = dist.rvs(100)\n",
    "        a[2] = dist.rvs(1000)\n",
    "        for j in range(3):\n",
    "            stats[j, :3, i] = np.array([a[j].mean(), np.median(a[j]), q_mid(a[j])])\n",
    "            stats[j, 3:, i] = stats[j, :3, i] ** 2\n",
    "    ans = stats.mean(axis=2)\n",
    "    ans[:, 3:] = ans[:, 3:]-ans[:,:3]**2\n",
    "    ans = pd.DataFrame(ans, columns=['Mean','Median','$z_Q$', 'Mean variance','Median variance','$z_Q$ variance'])\n",
    "    ans = pd.concat((pd.DataFrame(np.array([10, 100, 1000]), columns=['Sample size']), ans), axis=1)\n",
    "    for i in range(3):\n",
    "        ans['Mean'][i] = format_value_with_uncertainty(ans['Mean'][i], ans['Mean variance'][i], ans['Sample size'][i])\n",
    "        ans['Median'][i] = format_value_with_uncertainty(ans['Median'][i], ans['Median variance'][i], ans['Sample size'][i])\n",
    "        ans['$z_Q$'][i] = format_value_with_uncertainty(ans['$z_Q$'][i], ans['$z_Q$ variance'][i], ans['Sample size'][i])\n",
    "    return ans[['Sample size', 'Mean', 'Median', '$z_Q$']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144a223c-6639-40e0-80c0-1823d4ced5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_boxplot(dist, save_path=None):\n",
    "    a = dict()\n",
    "    a[10] = dist.rvs(20)\n",
    "    a[50] = dist.rvs(100)\n",
    "    a[1000] = dist.rvs(1000)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "    outliers = dict.fromkeys(a.keys())\n",
    "    for num, ax in zip(a.keys(), axes):\n",
    "        ax.set_title(f'Number of samples {num}')\n",
    "        bplot = ax.boxplot(a[num])\n",
    "        outliers[num] = len(bplot[\"fliers\"][0].get_ydata())\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dbe966-7a33-4c49-a9a4-099a7f5cce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureModel(stats.rv_continuous):\n",
    "    def __init__(self, submodels, *args, weights = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.submodels = submodels\n",
    "        if weights is None:\n",
    "            weights = [1 for _ in submodels]\n",
    "        if len(weights) != len(submodels):\n",
    "            raise(ValueError(f'There are {len(submodels)} submodels and {len(weights)} weights, but they must be equal.'))\n",
    "        self.weights = [w / sum(weights) for w in weights]\n",
    "        \n",
    "    def pdf(self, x):\n",
    "        pdf = self.submodels[0].pdf(x) * self.weights[0]\n",
    "        for submodel, weight in zip(self.submodels[1:], self.weights[1:]):\n",
    "            pdf += submodel.pdf(x)  * weight\n",
    "        return pdf\n",
    "            \n",
    "    def _sf(self, x):\n",
    "        sf = self.submodels[0].sf(x) * self.weights[0]\n",
    "        for submodel, weight in zip(self.submodels[1:], self.weights[1:]):\n",
    "            sf += submodel.sf(x)  * weight\n",
    "        return sf\n",
    "\n",
    "    def _cdf(self, x):\n",
    "        cdf = self.submodels[0].cdf(x) * self.weights[0]\n",
    "        for submodel, weight in zip(self.submodels[1:], self.weights[1:]):\n",
    "            cdf += submodel.cdf(x)  * weight\n",
    "        return cdf\n",
    "\n",
    "        \n",
    "\n",
    "    def rvs(self, size):\n",
    "        submodel_choices = np.random.choice(range(len(self.submodels)), size=size, p = self.weights)\n",
    "        submodel_samples = [submodel.rvs(size=size) for submodel in self.submodels]\n",
    "        rvs = np.empty(submodel_samples[0].shape)\n",
    "        for i, choice in enumerate(submodel_choices):\n",
    "            rvs[i] = submodel_samples[choice][i]\n",
    "        return rvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4dc84c-1fb3-4f07-84cf-4a96759d3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_statistics(dist):\n",
    "    statistics = dict.fromkeys([20, 60, 100], {'Pearson Corr': np.empty(1000), 'Spearman Corr': np.empty(1000)})\n",
    "    ans = dict.fromkeys([20, 60, 100], {'Pearson Corr': '', 'Spearman Corr': ''})\n",
    "    for i in range(1000):\n",
    "        a = {20: dist.rvs(20), 60: dist.rvs(60), 100: dist.rvs(100)}\n",
    "        for j in a.keys():\n",
    "            statistics[j]['Pearson Corr'][i] = stats.pearsonr(a[j][:, 0], a[j][:, 1]).statistic\n",
    "            statistics[j]['Spearman Corr'][i] = stats.spearmanr(a[j][:, 0], a[j][:, 1]).statistic\n",
    "    for k in statistics.keys():\n",
    "        m = np.mean(statistics[k]['Pearson Corr'])\n",
    "        v = np.var(statistics[k]['Pearson Corr'])\n",
    "        ans[k]['Pearson Corr'] = format_value_with_uncertainty(m, v, k)\n",
    "        m = np.mean(statistics[k]['Spearman Corr'])\n",
    "        v = np.var(statistics[k]['Spearman Corr'])\n",
    "        ans[k]['Spearman Corr'] = format_value_with_uncertainty(m, v, k)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd288b0-d007-4580-a048-cc3fbc3d4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level_lines(dist, plot_range_x, plot_range_y, save_path):\n",
    "    f = dist.pdf\n",
    "    x, y = np.mgrid[plot_range_x[0]:plot_range_x[1]:0.01*(plot_range_x[1]-plot_range_x[0]), plot_range_y[0]:plot_range_y[1]:0.01*(plot_range_y[1]-plot_range_y[0])]\n",
    "    pos = np.dstack((x, y))\n",
    "    z = f(pos)\n",
    "    plt.contour(x, y, z, levels=25)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f7f2b3-fa97-4cd6-bfd8-966222996316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LsS(x, y, true_a, true_b):\n",
    "    a = ((x*y).mean()-(x.mean()*y.mean()))/((x**2).mean()-(x.mean())**2)\n",
    "    b = y.mean()-x.mean()*a\n",
    "    print(a, a/true_a, b, b/true_b)\n",
    "    return a, a/true_a, b, b/true_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047a423b-a174-48fc-b34b-98d41b98494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def LAV(x, y, true_a, true_b):\n",
    "    def m_a_v(a, b):\n",
    "        return np.abs(a*x+b-y).mean()\n",
    "    w = minimize(lambda w: m_a_v(w[0], w[1]), (1, 1), method='Nelder-Mead').x\n",
    "    print(w[0], w[0]/true_a, w[1], w[1]/true_b)\n",
    "    return w[0], w[0]/true_a, w[1], w[1]/true_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d6d7f3-05b6-4bbe-9aad-4fbf6f4b3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_norm_test(samples, k, alpha):\n",
    "    treshhold = stats.chi2.ppf(1-alpha, k-1)\n",
    "    print(treshhold)\n",
    "    H_0_dist = stats.norm(*stats.norm.fit(samples))\n",
    "    bins = np.linspace(H_0_dist.mean()-3*H_0_dist.std(), H_0_dist.mean()+3*H_0_dist.std(), k-1, endpoint=True)\n",
    "    bins = np.append(bins, np.inf)\n",
    "    bins = np.insert(bins, 0, -np.inf)\n",
    "    P = H_0_dist.cdf(bins[1:])-H_0_dist.cdf(bins[:-1])\n",
    "    freq = np.histogram(samples, bins)[0]\n",
    "    statistics = ((freq-len(samples)*P)**2/(len(samples)*P))\n",
    "    criterion = statistics.sum()\n",
    "    if criterion >= treshhold:\n",
    "        result = 'Reject'\n",
    "    else:\n",
    "        result = 'Fail to reject'\n",
    "    table = pd.DataFrame(np.column_stack((bins[:-1].T, bins[1:], (bins[:-1]-H_0_dist.mean())/H_0_dist.std(), (bins[1:]-H_0_dist.mean())/H_0_dist.std(),\n",
    "                         P, statistics)), columns=['Left Edge', 'Right Edge', 'NLeft Edge', 'NRight Edge', 'Probability', 'Stat'])\n",
    "    return table, criterion, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ee6c14-be2c-4b42-a1b2-225c45cb2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab6(save_path):\n",
    "    X1 = np.random.normal(loc=0, scale=0.95, size=1000)\n",
    "    X2 = np.random.normal(loc=1, scale=1.05, size=1000)\n",
    "    \n",
    "    def inner_interval(data):\n",
    "        q1, q3 = np.percentile(data, [25, 75])\n",
    "        return (q1, q3)\n",
    "    \n",
    "    def outer_interval(data):\n",
    "        return (np.min(data), np.max(data))\n",
    "    \n",
    "    def jaccard_index(interval1, interval2):\n",
    "        a1, b1 = interval1\n",
    "        a2, b2 = interval2\n",
    "        intersection_start = max(a1, a2)\n",
    "        intersection_end = min(b1, b2)\n",
    "        if intersection_start >= intersection_end:\n",
    "            return 0.0\n",
    "        union_start = min(a1, a2)\n",
    "        union_end = max(b1, b2)\n",
    "        intersection_length = intersection_end - intersection_start\n",
    "        union_length = union_end - union_start\n",
    "        return intersection_length / union_length\n",
    "    \n",
    "    def calculate_J(a, X1, X2):\n",
    "        X1_shifted = X1 + a\n",
    "        im1 = inner_interval(X1_shifted)\n",
    "        im2 = inner_interval(X2)\n",
    "        out1 = outer_interval(X1_shifted)\n",
    "        out2 = outer_interval(X2)\n",
    "        return jaccard_index(im1, im2), jaccard_index(out1, out2)\n",
    "    \n",
    "    a_values = np.linspace(-2, 4, 1000)\n",
    "    J_Im = np.array([])\n",
    "    J_Out = np.array([])\n",
    "    \n",
    "    for a in a_values:\n",
    "        j_im, j_out = calculate_J(a, X1, X2)\n",
    "        J_Im = np.append(J_Im, j_im)\n",
    "        J_Out = np.append(J_Out, j_out)\n",
    "    \n",
    "    # Построение графиков\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(a_values, J_Im, label='$J_{Im}$')\n",
    "    plt.plot(a_values, J_Out, label='$J_{Out}$')\n",
    "    plt.xlabel('$a$')\n",
    "    plt.ylabel('Индекс Жаккара')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Нахождение оптимальных a\n",
    "    a_Im = a_values[np.argwhere(np.isclose(J_Im, np.max(J_Im), rtol=1e-3))]\n",
    "    a_Out = a_values[np.argwhere(np.isclose(J_Out, np.max(J_Out), rtol=1e-3))]\n",
    "    \n",
    "    print(np.min(a_Im), np.max(a_Im))\n",
    "    print(np.min(a_Out), np.max(a_Out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0e7fe6a-2e60-4e6c-937a-7c6167a5e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, norm, chi2\n",
    "\n",
    "def normal_mean_ci(x_bar, s, n, alpha):\n",
    "    dof = n - 1\n",
    "    t_crit = t.ppf(1 - alpha/2, dof)\n",
    "    margin = t_crit * s / np.sqrt(n-1)\n",
    "    return (x_bar - margin, x_bar + margin)\n",
    "\n",
    "def normal_std_ci(s, n, alpha):\n",
    "    dof = n - 1\n",
    "    chi2_lower = chi2.ppf(alpha/2, dof)\n",
    "    chi2_upper = chi2.ppf(1 - alpha/2, dof)\n",
    "    lower = s * np.sqrt(n) / np.sqrt(chi2_upper)\n",
    "    upper = s * np.sqrt(n) / np.sqrt(chi2_lower)\n",
    "    return (lower, upper)\n",
    "\n",
    "def asymptotic_mean_ci(x_bar, s, n, alpha):\n",
    "    u_crit = norm.ppf(1 - alpha/2)\n",
    "    margin = u_crit * s / np.sqrt(n)\n",
    "    return (x_bar - margin, x_bar + margin)\n",
    "\n",
    "def asymptotic_std_ci(s, n, alpha, e):\n",
    "    u_crit = norm.ppf(1 - alpha/2)\n",
    "    U = u_crit * np.sqrt((e + 2) / n)\n",
    "    lower = s * (1 - 0.5 * U)\n",
    "    upper = s * (1 + 0.5 * U)\n",
    "    return (lower, upper)\n",
    "\n",
    "def lab7():\n",
    "    alpha = 0.05\n",
    "    sample_sizes = [20, 100]\n",
    "    \n",
    "    normal_samples = {\n",
    "        20: np.random.normal(loc=0, scale=1, size=20),\n",
    "        100: np.random.normal(loc=0, scale=1, size=100)\n",
    "    }\n",
    "\n",
    "    exp_samples = {\n",
    "        20: np.random.exponential(scale=1, size=20),\n",
    "        100: np.random.exponential(scale=1, size=100)\n",
    "    }\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        x_bar = np.mean(normal_samples[n])\n",
    "        s = np.std(normal_samples[n], ddof=1)\n",
    "        m_low, m_high = normal_mean_ci(x_bar, s, n, alpha)\n",
    "        sigma_low, sigma_high = normal_std_ci(s, n, alpha)\n",
    "        print(f\"Size {n} Normal \\n ({m_low:.3f} < {x_bar:.3f} < {m_high:.3f})\")\n",
    "        print(f\"({sigma_low:.3f} < {s:.3f} < {sigma_high:.3f})\")\n",
    "\n",
    "        x_bar = np.mean(exp_samples[n])\n",
    "        s = np.std(exp_samples[n], ddof=1)\n",
    "        e = stats.moment(exp_samples[n], 4)/(s **4)-3\n",
    "        m_low, m_high = asymptotic_mean_ci(x_bar, s, n, alpha)\n",
    "        sigma_low, sigma_high = asymptotic_std_ci(s, n, alpha, e)\n",
    "        print(f\"Size {n} Exp \\n ({m_low:.3f} < {x_bar:.3f} < {m_high:.3f})\")\n",
    "        print(f\"({sigma_low:.3f} < {s} < {sigma_high:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d8e419-0a1d-41cb-872d-1752653e638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 20 Normal \n",
      " (-0.698 < -0.091 < 0.515)\n",
      "(0.985 < 1.263 < 1.892)\n",
      "Size 20 Exp \n",
      " (0.496 < 0.968 < 1.440)\n",
      "(0.740 < 1.0774007033717594 < 1.415)\n",
      "Size 100 Normal \n",
      " (-0.277 < -0.075 < 0.127)\n",
      "(0.893 < 1.011 < 1.181)\n",
      "Size 100 Exp \n",
      " (0.794 < 0.997 < 1.200)\n",
      "(0.766 < 1.0365852292048057 < 1.307)\n"
     ]
    }
   ],
   "source": [
    "lab7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639776e6-9a91-4dec-8321-564917e9e497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
